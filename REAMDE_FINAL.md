
# Решение соревнования по предсказанию выживаемости после HCT

## Реализованное решение

Решение основывается на ансамбле из шести моделей: **CatBoost**, **XGBoost**, **LightGBM (GBDT)**, **LightGBM (DART)**, **TabNet** и **Deep Neural Network**. Предсказания всех моделей усредняются для получения финального результата.

## Проделанная работа:

### 1. Загружены и подготовлены данные
- Использованы библиотеки `pandas`, `numpy`, `torch`, `sklearn`, `catboost`, `xgboost`, `lightgbm` и `pytorch_tabnet`
- Загружены данные из `train.csv` и `test.csv`
- Применена комплексная обработка пропущенных значений и категориальных признаков
- Созданы дополнительные признаки (HCT-CI score, donor_recipient_age_diff, hla_match_ratio и др.)

### 2. Разработаны и обучены традиционные модели машинного обучения
- **CatBoost** с нативной поддержкой категориальных признаков
- **XGBoost** с оптимизированными гиперпараметрами
- **LightGBM** с двумя вариантами бустинга (GBDT и DART) для разнообразия ансамбля

### 3. Реализованы модели глубокого обучения
- **TabNet** - специализированная архитектура для табличных данных с механизмом внимания
- **Кастомная DNN** - глубокая нейронная сеть с embedding слоями для категориальных признаков и BatchNorm для стабилизации обучения

### 4. Реализовано кросс-валидационное обучение
- Использована KFold стратегия для обеспечения устойчивости моделей
- Для каждого сплита обучаются отдельные модели
- Финальное предсказание - усреднение результатов всех моделей на всех фолдах

### 5. Особенности обработки категориальных признаков
- Для **CatBoost** использован нативный подход
- Для **XGBoost** и **LightGBM** применен LabelEncoder
- Для **TabNet** реализована специальная предобработка с преобразованием строковых категорий в числовые
- Для **DNN** созданы embedding-векторы категориальных признаков

### 6. Реализована надежная система обработки ошибок
- Изолированы ошибки каждой модели для стабильности ансамбля
- Добавлены проверки размерностей и типов данных
- Реализовано логирование для отладки

## Дальнейшие улучшения:

### 1. Оптимизация гиперпараметров
- Применение **Optuna** или **Bayesian Optimization** для всех моделей
- Поиск оптимальных архитектур для TabNet и DNN

### 2. Развитие инженерии признаков
- Создание более сложных взаимодействий между признаками
- Применение методов снижения размерности (PCA, t-SNE)
- Использование domain knowledge для создания медицински значимых признаков

### 3. Мета-моделирование
- Добавление мета-уровня, использующего предсказания базовых моделей
- Обучение стекинг-модели для оптимального взвешивания предсказаний

### 4. Улучшение DL-моделей
- Применение self-attention механизмов для TabNet
- Тестирование различных архитектур DNN (ResNet, Highway Networks)
- Реализация предварительного обучения (pre-training) эмбеддингов

### 5. Анализ важности признаков
- SHAP-анализ для всех моделей
- Интерпретация механизма внимания TabNet
- Визуализация эмбеддингов категориальных признаков

### 6. Валидация решения
- Тестирование устойчивости модели на разных подгруппах данных
- Проверка стабильности предсказаний между разными запусками
- Анализ калибровки вероятностей предсказаний
