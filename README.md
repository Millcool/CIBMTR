# CIBMTR
Kaggle сореванование

Решение основывается на ансамбле двух моделей
Catboost + Xgboost, ответы которых берутся средневзвешенно

Проделанная работа:
1. Загружены необходимые библиотеки – используются numpy, pandas, catboost, xgboost, sklearn и LabelEncoder для обработки данных и построения моделей.
2. Загружены данные – считаны train.csv и test.csv с помощью pandas.
3. Произведено разбиение на обучающую и валидационную выборки.
4. Я использовал просс валидацию про обучении Catboost и XGboost 
5. Категориальные признаки обрабатал LabelEncoder 
6. Сделал ансамбль моделей которые дают средневзвешенный результат
7. Формирую прогноз и файл для отправки.

Дальнейшие улучшения
1. Сделаю мета модель для более точного предстазания, которая будет основываться на Catboost и Xgboost предсказаниях
2. Сделаю более сложную предобработку признаков
3. Сделаю анализ важности признаков
4. Сделаю тюнинг типерпараметров через GridSearch
5. Сделаю более сложный ансамбль
6. Подчищю данные 
